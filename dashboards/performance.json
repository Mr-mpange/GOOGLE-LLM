{
  "title": "LLM Guardian - Performance Dashboard",
  "description": "Performance monitoring for LLM application including latency, errors, and resource utilization",
  "widgets": [
    {
      "id": 1,
      "definition": {
        "type": "timeseries",
        "requests": [
          {
            "q": "avg:llm.request.latency{*}",
            "display_type": "line"
          },
          {
            "q": "p50:llm.request.latency{*}",
            "display_type": "line"
          },
          {
            "q": "p95:llm.request.latency{*}",
            "display_type": "line"
          },
          {
            "q": "p99:llm.request.latency{*}",
            "display_type": "line"
          }
        ],
        "title": "Latency Percentiles (p50, p95, p99)",
        "show_legend": true
      }
    },
    {
      "id": 2,
      "definition": {
        "type": "query_value",
        "requests": [
          {
            "q": "avg:llm.request.latency{*}",
            "aggregator": "avg"
          }
        ],
        "title": "Average Latency",
        "precision": 0,
        "custom_unit": "ms"
      }
    },
    {
      "id": 3,
      "definition": {
        "type": "timeseries",
        "requests": [
          {
            "q": "sum:llm.error.count{*}.as_rate()",
            "display_type": "bars",
            "style": {
              "palette": "warm"
            }
          }
        ],
        "title": "Error Rate",
        "show_legend": false
      }
    },
    {
      "id": 4,
      "definition": {
        "type": "query_value",
        "requests": [
          {
            "q": "(sum:llm.request.count{status:error}.as_count() / sum:llm.request.count{*}.as_count()) * 100",
            "aggregator": "avg"
          }
        ],
        "title": "Error Percentage",
        "precision": 2,
        "custom_unit": "%"
      }
    },
    {
      "id": 5,
      "definition": {
        "type": "timeseries",
        "requests": [
          {
            "q": "avg:system.cpu.user{service:llm-guardian}",
            "display_type": "area"
          }
        ],
        "title": "CPU Utilization",
        "show_legend": false
      }
    },
    {
      "id": 6,
      "definition": {
        "type": "timeseries",
        "requests": [
          {
            "q": "avg:system.mem.used{service:llm-guardian}",
            "display_type": "area"
          }
        ],
        "title": "Memory Usage",
        "show_legend": false
      }
    },
    {
      "id": 7,
      "definition": {
        "type": "heatmap",
        "requests": [
          {
            "q": "avg:llm.request.latency{*} by {endpoint}"
          }
        ],
        "title": "Latency Heatmap by Endpoint"
      }
    },
    {
      "id": 8,
      "definition": {
        "type": "timeseries",
        "requests": [
          {
            "q": "sum:llm.request.count{*}.as_rate()",
            "display_type": "bars"
          }
        ],
        "title": "Request Throughput",
        "show_legend": false
      }
    },
    {
      "id": 9,
      "definition": {
        "type": "distribution",
        "requests": [
          {
            "q": "avg:llm.request.latency{*}"
          }
        ],
        "title": "Latency Distribution"
      }
    },
    {
      "id": 10,
      "definition": {
        "type": "toplist",
        "requests": [
          {
            "q": "top(avg:llm.request.latency{*} by {endpoint}, 10, 'mean', 'desc')"
          }
        ],
        "title": "Slowest Endpoints"
      }
    }
  ],
  "layout_type": "ordered",
  "is_read_only": false,
  "notify_list": [],
  "template_variables": [
    {
      "name": "env",
      "default": "production",
      "prefix": "env"
    }
  ]
}
